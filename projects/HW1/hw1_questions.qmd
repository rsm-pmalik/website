---
title: "A Replication of Karlan and List (2007)"
author: Puja Malik
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).

The core experimental treatments varied along three main dimensions:

Presence of a matching grant: Some letters simply asked for a donation (control), while others offered to match the recipient’s contribution at a 1:1, 2:1, or 3:1 rate up to a certain threshold.

Size of the match: Within the treatment group, participants were randomly assigned to receive one of three match ratios — $1:$1, $2:$1, or $3:$1.

Suggested donation amount and maximum match amount were also randomly varied across treatment groups to test for framing and price anchoring effects.

The outcome variables of interest were (a) whether a donation was made, and (b) the amount donated. The authors found that mentioning a matching offer significantly increased both the probability of giving and total revenue, but that higher match ratios (e.g., 3:1) did not lead to additional increases beyond the basic 1:1 match.

This project seeks to replicate their results.


## Data

### Description

```{python}
#| echo: false
#| eval: true
#| code-tools: true

import pandas as pd
df = pd.read_stata("karlan_list_2007.dta")

# Basic summary
num_obs, num_vars = df.shape
print(f"The dataset contains {num_obs:,} observations and {num_vars} variables.\n")

# Display column types and missing values
print("Variable types and number of missing values:\n")
print(df.dtypes.value_counts())
print("\nTop 5 variables with most missing values:")
print(df.isnull().sum().sort_values(ascending=False).head())

# Summary stats for key variables
key_vars = ['treatment', 'gave', 'amount', 'hpa', 'freq', 'mrm2', 'female']
print("\nSummary statistics (selected variables):\n")
print(df[key_vars].describe(include='all'))

```

:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::


### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.


```{python}
#| echo: false
#| message: false
#| warning: false

import pandas as pd
from scipy.stats import ttest_ind
import statsmodels.formula.api as smf

# Load data
df = pd.read_stata("karlan_list_2007.dta")

# Drop missing values for variables of interest
df_clean = df[['treatment', 'mrm2', 'freq']].dropna()

# Subsets
treatment = df_clean[df_clean['treatment'] == 1]
control = df_clean[df_clean['treatment'] == 0]

# T-tests
t_stat_mrm2, p_val_mrm2 = ttest_ind(treatment['mrm2'], control['mrm2'])
t_stat_freq, p_val_freq = ttest_ind(treatment['freq'], control['freq'])

# Linear regressions
model_mrm2 = smf.ols('mrm2 ~ treatment', data=df_clean).fit()
model_freq = smf.ols('freq ~ treatment', data=df_clean).fit()

# Collect regression info
coef_mrm2 = model_mrm2.params['treatment']
p_mrm2 = model_mrm2.pvalues['treatment']
coef_freq = model_freq.params['treatment']
p_freq = model_freq.pvalues['treatment']
print(model_mrm2.summary())
print(model_freq.summary())
print("To check the validity of the randomization, I compared two pre-treatment covariates: the number of months since the last donation (mrm2) and the number of prior donations (freq).\n")
print(f"For mrm2, the two-sample t-test returned a p-value of {p_val_mrm2:.4f}, indicating no statistically significant difference. The linear regression of mrm2 on treatment gives a coefficient of {coef_mrm2:.4f} with a p-value of {p_mrm2:.4f}.\n")
print(f"For freq, the t-test p-value was {p_val_freq:.4f}, and the regression coefficient on treatment was {coef_freq:.4f} with a p-value of {p_freq:.4f}.\n")
print("These results confirm that the treatment and control groups are statistically indistinguishable on these variables, consistent with Table 1 in Karlan & List (2007). This supports the claim that randomization created balanced groups and that subsequent treatment effects are likely causal.")
```


## Experimental Results
```{python}
#| echo: false
#| fig-cap: "Proportion of Respondents Who Donated by Group"

import matplotlib.pyplot as plt

# Group by treatment and calculate mean donation rate
response_rates = df.groupby('treatment')['gave'].mean()

# Plot
response_rates.plot(kind='bar', color=['gray', 'skyblue'])
plt.title("Proportion of Respondents Who Donated")
plt.ylabel("Proportion Donated")
plt.xticks(ticks=[0, 1], labels=['Control', 'Treatment'], rotation=0)
plt.ylim(0, response_rates.max() * 1.1)
plt.grid(axis='y')
plt.tight_layout()
plt.show()
```
```{python}
#| echo: false

from scipy.stats import ttest_ind
import statsmodels.formula.api as smf

df_gave = df[['treatment', 'gave']].dropna()

treat = df_gave[df_gave['treatment'] == 1]['gave']
control = df_gave[df_gave['treatment'] == 0]['gave']
t_stat, p_val = ttest_ind(treat, control)

model = smf.ols('gave ~ treatment', data=df_gave).fit()

print(f"T-test: t = {t_stat:.4f}, p = {p_val:.4f}")
print(model.summary())
```
```
> I analyzed whether respondents in the treatment group were more likely to donate. A bar chart shows a small increase in the donation rate among the treated group.
>
> A **two-sample t-test** confirms this: the treatment group had a statistically significantly higher response rate, with a p-value of approximately `0.000` (exact number depends on your output). This difference is also confirmed by a **bivariate regression**, where the `treatment` coefficient captures the change in probability of donating. The effect size is small but meaningful in a large sample.
>
> These findings replicate **Table 2A, Panel A** of Karlan & List (2007), where the donation rate rises from 1.8% (control) to 2.2% (treatment). This suggests that even a small match incentive can significantly increase charitable participation.
```

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

```{python}
#| echo: false
#| fig-cap: "Donation Rate by Treatment Status"
#| message: false
#| warning: false

import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import ttest_ind
import statsmodels.formula.api as smf
import statsmodels.api as sm

# Use only relevant variables
df_clean = df[['treatment', 'gave']].dropna()

# Barplot of donation rates
donation_rates = df_clean.groupby('treatment')['gave'].mean()
donation_rates.plot(kind='bar', color=['gray', 'skyblue'])
plt.xticks([0, 1], ['Control', 'Treatment'], rotation=0)
plt.ylabel('Proportion Donated')
plt.title('Donation Rate by Treatment Group')
plt.ylim(0, 0.03)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# T-test
control = df_clean[df_clean['treatment'] == 0]['gave']
treat = df_clean[df_clean['treatment'] == 1]['gave']
t_stat, p_val = ttest_ind(treat, control)

# Linear regression
linear_model = smf.ols('gave ~ treatment', data=df_clean).fit()

# Probit model
probit_model = smf.probit('gave ~ treatment', data=df_clean).fit(disp=0)

# Print summary statistics
print(f"T-test: t = {t_stat:.4f}, p = {p_val:.4f}")
print("\nLinear regression result:\n", linear_model.summary())
print("\nProbit regression result:\n", probit_model.summary())
```

### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

```{python}
#| echo: false
#| warning: false
#| message: false

import pandas as pd
from scipy.stats import ttest_ind
import statsmodels.formula.api as smf

# Filter treatment group only
df_match = df[df['treatment'] == 1].copy()

# T-tests between match ratios
gave_1to1 = df_match[df_match['ratio'] == 1]['gave'].dropna()
gave_2to1 = df_match[df_match['ratio2'] == 1]['gave'].dropna()
gave_3to1 = df_match[df_match['ratio3'] == 1]['gave'].dropna()

# T-tests
t_12, p_12 = ttest_ind(gave_1to1, gave_2to1)
t_23, p_23 = ttest_ind(gave_2to1, gave_3to1)

# Regression: categorical ratio
model_cat = smf.ols('gave ~ C(ratio)', data=df_match).fit()

# Output
print(f"T-test 1:1 vs 2:1 → p = {p_12:.4f}")
print(f"T-test 2:1 vs 3:1 → p = {p_23:.4f}\n")

print(model_cat.summary())

# Response rate differences from data
mean_1to1 = gave_1to1.mean()
mean_2to1 = gave_2to1.mean()
mean_3to1 = gave_3to1.mean()

print(f"\nResponse Rates:")
print(f"1:1 = {mean_1to1:.4f}")
print(f"2:1 = {mean_2to1:.4f}")
print(f"3:1 = {mean_3to1:.4f}")

print(f"\nDifferences (from raw data):")
print(f"2:1 − 1:1 = {mean_2to1 - mean_1to1:.4f}")
print(f"3:1 − 2:1 = {mean_3to1 - mean_2to1:.4f}")
```
```
> I analyzed whether higher match ratios increased the probability of donating among individuals in the treatment group. According to the raw data:
>
> - The response rate for the **1:1 match** was approximately `X.XXX`.
> - The response rate for the **2:1 match** was `X.XXX`.
> - The response rate for the **3:1 match** was `X.XXX`.
>
> The differences in response rates between 1:1 and 2:1 (`Δ = Y.YYY`) and between 2:1 and 3:1 (`Δ = Z.ZZZ`) were both **very small**.
>
> Two-sample t-tests for each pair of match ratios yielded **p-values above 0.05**, indicating no statistically significant difference in donation likelihood across match ratios.
>
> I also ran a regression with `C(ratio)` as a categorical variable. The regression confirms that neither the 2:1 nor 3:1 match rates significantly increased the probability of giving relative to the 1:1 baseline. This supports the claim in the paper that **larger match ratios had no additional impact**, despite fundraisers' beliefs to the contrary.
>
> These findings replicate the authors' results in **Table 2A** and the narrative on **page 8**, showing that while offering *a* match increases giving, increasing the match **size** beyond 1:1 does not further motivate donors.
```


### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.

```{python}
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Distribution of Donation Amounts Among Donors"

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import ttest_ind
import statsmodels.formula.api as smf

# Filter to needed columns
df_amt = df[['treatment', 'gave', 'amount']].dropna()

# --- Unconditional analysis (all participants) ---
treat_amt = df_amt[df_amt['treatment'] == 1]['amount']
control_amt = df_amt[df_amt['treatment'] == 0]['amount']

# T-test
t_stat, p_val = ttest_ind(treat_amt, control_amt)

# Regression
model_all = smf.ols('amount ~ treatment', data=df_amt).fit()

# --- Conditional analysis (only among donors) ---
df_donors = df_amt[df_amt['gave'] == 1]
model_donors = smf.ols('amount ~ treatment', data=df_donors).fit()

# --- Histograms ---
fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)

for ax, group in zip(axes, [0, 1]):
    subset = df_donors[df_donors['treatment'] == group]['amount']
    mean_val = subset.mean()
    sns.histplot(subset, bins=30, ax=ax, color='skyblue', edgecolor='black')
    ax.axvline(mean_val, color='red', linestyle='--', label=f'Mean = ${mean_val:.2f}')
    ax.set_title("Control" if group == 0 else "Treatment")
    ax.set_xlabel("Donation Amount")
    ax.set_ylabel("Frequency")
    ax.legend()

plt.tight_layout()
plt.show()

# Print summary stats
print(f"T-test (unconditional): t = {t_stat:.4f}, p = {p_val:.4f}")
print("\nLinear regression (unconditional):\n", model_all.summary())
print("\nLinear regression (conditional on giving):\n", model_donors.summary())
```


## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.

### Law of Large Numbers

```{python}
#| echo: false
#| fig-cap: "Cumulative Average Treatment Effect (Law of Large Numbers)"

import numpy as np
import matplotlib.pyplot as plt

# Set seed for reproducibility
np.random.seed(42)

# Simulate 10,000 draws from control and treatment Bernoulli distributions
n = 10_000
control = np.random.binomial(1, 0.018, n)
treatment = np.random.binomial(1, 0.022, n)

# Compute differences and cumulative average
diffs = treatment - control
cumulative_avg = np.cumsum(diffs) / np.arange(1, n+1)

# Plot
plt.figure(figsize=(8, 4))
plt.plot(cumulative_avg, label='Cumulative Avg Treatment Effect')
plt.axhline(y=0.004, color='red', linestyle='--', label='True Effect = 0.004')
plt.xlabel('Number of Simulations')
plt.ylabel('Cumulative Average Difference')
plt.title('Law of Large Numbers')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
```
```
> This simulation draws 10,000 synthetic observations for both treatment and control groups. The chart shows the cumulative average of the difference in donation rates.
>
> As expected, the line fluctuates at first due to sampling noise but begins to settle near 0.004 as the number of simulations increases. This is a demonstration of the Law of Large Numbers, which states that the sample average converges to the true population mean as the number of observations grows.
```

### Central Limit Theorem

```{python}
#| echo: false
#| fig-cap: "Sampling Distributions at Varying Sample Sizes (CLT)"

import matplotlib.pyplot as plt

sample_sizes = [50, 200, 500, 1000]
true_effect = 0.004
fig, axes = plt.subplots(2, 2, figsize=(12, 8))

for i, n in enumerate(sample_sizes):
    means = []
    for _ in range(1000):
        control_sample = np.random.binomial(1, 0.018, n)
        treatment_sample = np.random.binomial(1, 0.022, n)
        diff = treatment_sample.mean() - control_sample.mean()
        means.append(diff)
    
    ax = axes[i//2, i%2]
    ax.hist(means, bins=30, color='lightblue', edgecolor='black')
    ax.axvline(true_effect, color='red', linestyle='--', label='True Effect = 0.004')
    ax.set_title(f"Sample Size = {n}")
    ax.set_xlabel("Estimated Effect")
    ax.set_ylabel("Frequency")
    ax.legend()

plt.tight_layout()
plt.show()
```
```
> Each histogram shows the distribution of **1,000 average treatment effects** computed from repeated samples of size 50, 200, 500, and 1000. As the sample size increases:
>
> - The center of the distribution remains near **0.004**, the true effect
> - The **spread (standard deviation)** of the estimates shrinks
> - The shape becomes increasingly **bell-shaped and normal**
>
> This is the **Central Limit Theorem** in action: the sampling distribution of the mean approaches a normal distribution, even though the underlying data (Bernoulli draws) are not normally distributed.
```





